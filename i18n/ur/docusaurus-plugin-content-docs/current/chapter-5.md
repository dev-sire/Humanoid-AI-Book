---
id: chapter-5
title: "باب 5: ویژن-لینگویج-ایکشن (VLA) ماڈلز"
sidebar_label: "باب 5: ویژن-لینگویج-ایکشن (VLA) ماڈلز"
week: 8-9
---

## جائزہ

اس باب میں وژن-لینگویج-ایکشن (VLA) ماڈلز کا مطالعہ کیا گیا ہے، جو کہ AI کا ایک جدید ترین علاقہ ہے جو روبوٹ کو زیادہ انسانوں کی طرح دنیا کو سمجھنے اور اس کے ساتھ بات چیت کرنے کے قابل بناتا ہے۔

## مقاصد

- VLA ماڈلز کے فن تعمیر کو سمجھیں۔
- دریافت کریں کہ کس طرح VLAs روبوٹکس میں استعمال ہوتے ہیں۔
- VLAs کے چیلنجز اور مستقبل کے بارے میں جانیں۔

## بنیادی مواد

Vision-Language-Action (VLA) ماڈلز AI ماڈل کی ایک قسم ہیں جو متعدد طریقوں سے معلومات کو پروسیس اور سمجھ سکتی ہے، بشمول وژن (تصاویر، ویڈیو)، زبان (ٹیکسٹ) اور ایکشن (روبوٹ کنٹرول سگنلز)۔ اس سے انہیں وہ کام انجام دینے کی اجازت ملتی ہے جن کے لیے دنیا کی گہری سمجھ کی ضرورت ہوتی ہے، جیسے کہ اشیاء میں ہیرا پھیری کے لیے قدرتی زبان کی ہدایات پر عمل کرنا۔

### فن تعمیر

VLA ماڈل عام طور پر تین اہم اجزاء پر مشتمل ہوتے ہیں:

- **وژن انکوڈر**: بصری ان پٹ پر کارروائی کرتا ہے اور متعلقہ خصوصیات کو نکالتا ہے۔
- **Language Encoder**: متنی ان پٹ پر کارروائی کرتا ہے اور متعلقہ خصوصیات کو نکالتا ہے۔
- **ایکشن ڈیکوڈر**: فیوزڈ ویژن اور لینگویج فیچرز کو بطور ان پٹ لیتا ہے اور ایکشنز کا ایک سلسلہ تیار کرتا ہے۔

## مثالیں۔

### ایک تصوراتی VLA ماڈل

اگرچہ VLA ماڈل کا مکمل نفاذ اس کتاب کے دائرہ کار سے باہر ہے، یہاں ایک تصوراتی مثال ہے کہ آپ روبوٹ کو کنٹرول کرنے کے لیے پہلے سے تربیت یافتہ VLA ماڈل کا استعمال کیسے کر سکتے ہیں۔

`` ازگر
numpy کو بطور np درآمد کریں۔
vla_model درآمد VLAModel سے

# پہلے سے تربیت یافتہ VLA ماڈل لوڈ کریں۔
vla = VLAModel.from_pretrained("google/rt-1-x")

# روبوٹ کے کیمرے سے تصویر حاصل کریں۔
تصویر = get_camera_image()

# قدرتی زبان کی ہدایات حاصل کریں۔
ہدایات = "سرخ بلاک اٹھاؤ"

# اعمال کی ترتیب بنانے کے لیے VLA ماڈل کا استعمال کریں۔
اعمال = vla.predict (تصویر، ہدایات)

# روبوٹ پر کارروائیوں کو انجام دیں۔
اعمال میں عمل کے لیے: 
robot.execute(ایکشن)
``

## اعداد و شمار

![VLA ماڈل آرکیٹیکچر](../../../../static/img/chap-5.png)

*شکل 1: ویژن-لینگویج-ایکشن (VLA) ماڈل کا ایک اعلیٰ سطحی خاکہ، جس میں وژن اور زبان کے انکوڈرز اور ایکشن ڈیکوڈر کو دکھایا گیا ہے۔*

## خلاصہ

اس باب میں وژن-لینگویج-ایکشن (VLA) ماڈلز اور ان کے فن تعمیر کو متعارف کرایا گیا۔ ہم نے ایک تصوراتی مثال دیکھی کہ کس طرح VLA ماڈل کو قدرتی زبان کی ہدایات پر مبنی روبوٹ کو کنٹرول کرنے کے لیے استعمال کیا جا سکتا ہے۔ آخری باب میں، ہم انسان نما روبوٹس پر AI ماڈلز کی تعیناتی کے چیلنجوں اور عملی تحفظات پر بات کریں گے۔